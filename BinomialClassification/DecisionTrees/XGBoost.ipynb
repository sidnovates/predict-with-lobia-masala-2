{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmwufBN1R0Jn",
        "outputId": "daa454f1-cf13-49fc-a997-deeee7495009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy pandas scikit-learn scikit-optimize xgboost scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFl5pcJ6oQ5g",
        "outputId": "20907257-1679-4a5c-a60d-bd3662060fa1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.7.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost_simple_splits.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ==========================================================\n",
        "# CONFIG\n",
        "# ==========================================================\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# -------- CHANGE THIS FOR GOOGLE COLAB --------\n",
        "BASE_OUTPUT_DIR = \"/content/drive/MyDrive/ML_Project/DecisionTrees/XGBoost\"\n",
        "os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
        "# -----------------------------------------------\n",
        "\n",
        "train_path = r\"/content/drive/MyDrive/ML_Project/Dataset/train_updated.csv\"\n",
        "test_path  = r\"/content/drive/MyDrive/ML_Project/Dataset/test_updated.csv\"\n",
        "\n",
        "TARGET = \"RiskFlag\"\n",
        "ID_COL = \"ProfileID\"\n",
        "\n",
        "numeric_features = [\n",
        "    \"ApplicantYears\",\"AnnualEarnings\",\"RequestedSum\",\"TrustMetric\",\"WorkDuration\",\n",
        "    \"ActiveAccounts\",\"OfferRate\",\"RepayPeriod\",\"DebtFactor\"\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    \"QualificationLevel\",\"WorkCategory\",\"RelationshipStatus\",\"FamilyObligation\",\n",
        "    \"OwnsProperty\",\"FundUseCase\",\"JointApplicant\"\n",
        "]\n",
        "\n",
        "# ==========================================================\n",
        "# LOAD DATA\n",
        "# ==========================================================\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# PREPROCESSOR\n",
        "# ==========================================================\n",
        "def make_preprocessor():\n",
        "    return ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", StandardScaler(), numeric_features),\n",
        "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# SAVE REPORTS & SUBMISSION\n",
        "# ==========================================================\n",
        "def save_outputs(model, preproc, out_dir,\n",
        "                 X_val, y_val, X_test_int, y_test_int, X_final):\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Transform data\n",
        "    X_val_p = preproc.transform(X_val)\n",
        "    X_test_p = preproc.transform(X_test_int)\n",
        "    X_final_p = preproc.transform(X_final)\n",
        "\n",
        "    # Predictions\n",
        "    val_pred = model.predict(X_val_p)\n",
        "    test_pred = model.predict(X_test_p)\n",
        "    final_pred = model.predict(X_final_p)\n",
        "\n",
        "    # Accuracies\n",
        "    val_acc = accuracy_score(y_val, val_pred)\n",
        "    test_acc = accuracy_score(y_test_int, test_pred)\n",
        "\n",
        "    # Validation Report\n",
        "    with open(os.path.join(out_dir, \"classification_validation.txt\"), \"w\") as f:\n",
        "        f.write(classification_report(y_val, val_pred))\n",
        "        f.write(f\"\\nValidation Accuracy: {val_acc}\\n\")\n",
        "\n",
        "    # Test Report\n",
        "    with open(os.path.join(out_dir, \"classification_test.txt\"), \"w\") as f:\n",
        "        f.write(classification_report(y_test_int, test_pred))\n",
        "        f.write(f\"\\nTest Accuracy: {test_acc}\\n\")\n",
        "\n",
        "    # Accuracy Summary\n",
        "    with open(os.path.join(out_dir, \"accuracy_summary.txt\"), \"w\") as f:\n",
        "        f.write(f\"Validation Accuracy: {val_acc}\\n\")\n",
        "        f.write(f\"Test Accuracy: {test_acc}\\n\")\n",
        "\n",
        "    # Submission CSV\n",
        "    submission = pd.DataFrame({\n",
        "        \"ProfileID\": test_df[ID_COL],\n",
        "        \"RiskFlag\": final_pred.astype(int)\n",
        "    })\n",
        "    submission.to_csv(os.path.join(out_dir, f\"{os.path.basename(out_dir)}_XGBoost.csv\"), index=False)\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# SIMPLE XGBOOST TRAINING\n",
        "# ==========================================================\n",
        "def run_simple(out_dir, X_train, y_train, X_val, y_val,\n",
        "               X_test_int, y_test_int, X_final, scale_pos_wt):\n",
        "\n",
        "    preproc = make_preprocessor()\n",
        "    X_train_p = preproc.fit_transform(X_train)\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=400,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        min_child_weight=1,\n",
        "        gamma=0,\n",
        "        random_state=SEED,\n",
        "        eval_metric=\"logloss\",\n",
        "        scale_pos_weight=scale_pos_wt\n",
        "    )\n",
        "\n",
        "    print(f\"Training simple XGBoost → {out_dir}\")\n",
        "\n",
        "    model.fit(X_train_p, y_train)\n",
        "\n",
        "    save_outputs(model, preproc, out_dir,\n",
        "                 X_val, y_val, X_test_int, y_test_int, X_final)\n",
        "\n",
        "    print(f\"Completed {out_dir}\\n\")\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# MAIN SCRIPT\n",
        "# ==========================================================\n",
        "def main():\n",
        "\n",
        "    # -----------------------------\n",
        "    # Dataset Splits\n",
        "    # -----------------------------\n",
        "    train_full, test_internal = train_test_split(\n",
        "        train_df, test_size=0.10, stratify=train_df[TARGET], random_state=SEED\n",
        "    )\n",
        "\n",
        "    train_80, val_10 = train_test_split(\n",
        "        train_full, test_size=0.1111,\n",
        "        stratify=train_full[TARGET], random_state=SEED\n",
        "    )\n",
        "\n",
        "    train_20_raw = train_test_split(\n",
        "        train_df, train_size=0.20,\n",
        "        stratify=train_df[TARGET], random_state=SEED\n",
        "    )[0]\n",
        "\n",
        "    train_20, val_20 = train_test_split(\n",
        "        train_20_raw, test_size=0.1111,\n",
        "        stratify=train_20_raw[TARGET], random_state=SEED\n",
        "    )\n",
        "\n",
        "    # Prepare test data\n",
        "    X_test_int = test_internal.drop([TARGET, ID_COL], axis=1)\n",
        "    y_test_int = test_internal[TARGET].values\n",
        "    X_final = test_df.drop(ID_COL, axis=1)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Modes\n",
        "    # -----------------------------\n",
        "    modes = [\n",
        "        (\"80_skewed\",      train_80, val_10, None),\n",
        "        (\"80_nonskewed\",   train_80, val_10, \"balanced\"),\n",
        "        (\"20_skewed\",      train_20, val_20, None),\n",
        "        (\"20_nonskewed\",   train_20, val_20, \"balanced\")\n",
        "    ]\n",
        "\n",
        "    for mode_name, train_split, val_split, balance in modes:\n",
        "\n",
        "        print(f\"\\n==============================\")\n",
        "        print(f\"   Running: {mode_name}\")\n",
        "        print(f\"==============================\\n\")\n",
        "\n",
        "        X_train = train_split.drop([TARGET, ID_COL], axis=1)\n",
        "        y_train = train_split[TARGET].values\n",
        "\n",
        "        X_val = val_split.drop([TARGET, ID_COL], axis=1)\n",
        "        y_val = val_split[TARGET].values\n",
        "\n",
        "        # Imbalance handling\n",
        "        if balance == \"balanced\":\n",
        "            pos = sum(y_train == 1)\n",
        "            neg = sum(y_train == 0)\n",
        "            spw = neg / pos\n",
        "        else:\n",
        "            spw = 1\n",
        "\n",
        "        # Output directory INSIDE Google Drive\n",
        "        out_dir = os.path.join(BASE_OUTPUT_DIR, mode_name)\n",
        "\n",
        "        run_simple(out_dir, X_train, y_train, X_val, y_val,\n",
        "                   X_test_int, y_test_int, X_final, spw)\n",
        "\n",
        "    print(\"\\nAll SIMPLE XGBoost Modes Completed Successfully!\\n\")\n",
        "\n",
        "\n",
        "# Run everything\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5-rPxS8oHHX",
        "outputId": "0e635809-651a-453f-cb39-7c78509674e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "   Running: 80_skewed\n",
            "==============================\n",
            "\n",
            "Training simple XGBoost → /content/drive/MyDrive/ML_Project/DecisionTrees/XGBoost/80_skewed\n",
            "Completed /content/drive/MyDrive/ML_Project/DecisionTrees/XGBoost/80_skewed\n",
            "\n",
            "\n",
            "==============================\n",
            "   Running: 80_nonskewed\n",
            "==============================\n",
            "\n",
            "Training simple XGBoost → /content/drive/MyDrive/ML_Project/DecisionTrees/XGBoost/80_nonskewed\n",
            "Completed /content/drive/MyDrive/ML_Project/DecisionTrees/XGBoost/80_nonskewed\n",
            "\n",
            "\n",
            "==============================\n",
            "   Running: 20_skewed\n",
            "==============================\n",
            "\n",
            "Training simple XGBoost → /content/drive/MyDrive/ML_Project/DecisionTrees/XGBoost/20_skewed\n",
            "Completed /content/drive/MyDrive/ML_Project/DecisionTrees/XGBoost/20_skewed\n",
            "\n",
            "\n",
            "==============================\n",
            "   Running: 20_nonskewed\n",
            "==============================\n",
            "\n",
            "Training simple XGBoost → /content/drive/MyDrive/ML_Project/DecisionTrees/XGBoost/20_nonskewed\n",
            "Completed /content/drive/MyDrive/ML_Project/DecisionTrees/XGBoost/20_nonskewed\n",
            "\n",
            "\n",
            "All SIMPLE XGBoost Modes Completed Successfully!\n",
            "\n"
          ]
        }
      ]
    }
  ]
}