{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network with SMOTE and Bayesian Optimization\n",
        "\n",
        "This notebook implements a Neural Network model with SMOTE for class balancing and Bayesian Optimization (Optuna) for hyperparameter tuning. It includes:\n",
        "1. Data Loading and Preprocessing\n",
        "2. Feature Engineering (K-Means)\n",
        "3. SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "4. Bayesian Hyperparameter Optimization\n",
        "5. Model Training\n",
        "6. Model Saving\n",
        "7. Model Loading and Prediction on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "import optuna\n",
        "import tensorflow as pd_tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Try importing SMOTE, fallback to manual upsampling if not available\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    HAS_SMOTE = True\n",
        "except ImportError:\n",
        "    HAS_SMOTE = False\n",
        "    print(\"imblearn not found. Using manual upsampling instead of SMOTE.\")\n",
        "\n",
        "# =====================================================\n",
        "# CONFIGURATION\n",
        "# =====================================================\n",
        "TRAIN_PATH = \"../../Dataset/train.csv\"\n",
        "TEST_PATH = \"../../Dataset/test.csv\"\n",
        "MODEL_SAVE_PATH = \"nn_smote_model.keras\"\n",
        "PIPELINE_SAVE_PATH = \"nn_pipeline.pkl\"\n",
        "SUBMISSION_PATH = \"submission_nn.csv\"\n",
        "TARGET = \"spend_category\"\n",
        "ID_COL = \"trip_id\"\n",
        "N_CLUSTERS = 6\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# DATA LOADING AND PREPROCESSING FUNCTIONS\n",
        "# =====================================================\n",
        "\n",
        "def load_data():\n",
        "    train_df = pd.read_csv(TRAIN_PATH)\n",
        "    test_df = pd.read_csv(TEST_PATH)\n",
        "    return train_df, test_df\n",
        "\n",
        "def preprocess_data(df, is_train=True):\n",
        "    df = df.copy()\n",
        "    \n",
        "    # 1. Clean strings\n",
        "    for c in df.columns:\n",
        "        if df[c].dtype == object:\n",
        "            df[c] = df[c].astype(str).str.strip().str.rstrip(',')\n",
        "            \n",
        "    # 2. Binary Columns\n",
        "    binary_cols = [\n",
        "        \"is_first_visit\",\"intl_transport_included\",\"accomodation_included\",\n",
        "        \"food_included\",\"domestic_transport_included\",\"sightseeing_included\",\n",
        "        \"guide_included\",\"insurance_included\"\n",
        "    ]\n",
        "    for c in binary_cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(str).str.strip().str.lower()\n",
        "            df[c] = df[c].replace({\"yes\": 1, \"no\": 0}).fillna(0)\n",
        "            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "    # 3. Numeric Count Columns\n",
        "    numeric_count_cols = [\"num_females\",\"num_males\",\"mainland_stay_nights\",\"island_stay_nights\"]\n",
        "    for c in numeric_count_cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "    # 4. Ordinal Encoding\n",
        "    def clean_str(x):\n",
        "        x = str(x).strip().lower()\n",
        "        if x in [\"nan\", \"none\", \"null\", \"\"]:\n",
        "            return np.nan\n",
        "        return x\n",
        "\n",
        "    if \"days_booked_before_trip\" in df.columns:\n",
        "        df[\"days_booked_before_trip_clean\"] = df[\"days_booked_before_trip\"].apply(clean_str)\n",
        "        ordinal_days = {\"1-7\": 1, \"8-14\": 2, \"15-30\": 3, \"31-60\": 4, \"61-90\": 5, \"90+\": 6}\n",
        "        df[\"days_booked_before_trip_ord\"] = df[\"days_booked_before_trip_clean\"].map(ordinal_days)\n",
        "        mode_val = df[\"days_booked_before_trip_ord\"].mode()[0] if not df[\"days_booked_before_trip_ord\"].mode().empty else 1\n",
        "        df[\"days_booked_before_trip_ord\"] = df[\"days_booked_before_trip_ord\"].fillna(mode_val).astype(int)\n",
        "\n",
        "    if \"total_trip_days\" in df.columns:\n",
        "        df[\"total_trip_days_clean\"] = df[\"total_trip_days\"].apply(clean_str)\n",
        "        ordinal_trip = {\"1-6\": 1, \"7-14\": 2, \"15-30\": 3, \"30+\": 4}\n",
        "        df[\"total_trip_days_ord\"] = df[\"total_trip_days_clean\"].map(ordinal_trip)\n",
        "        mode_val = df[\"total_trip_days_ord\"].mode()[0] if not df[\"total_trip_days_ord\"].mode().empty else 1\n",
        "        df[\"total_trip_days_ord\"] = df[\"total_trip_days_ord\"].fillna(mode_val).astype(int)\n",
        "\n",
        "    if \"has_special_requirements\" in df.columns:\n",
        "        df[\"has_special_req_bin\"] = df[\"has_special_requirements\"].astype(str).apply(\n",
        "            lambda x: 0 if x.lower() in [\"none\", \"\", \"nan\"] else 1\n",
        "        )\n",
        "\n",
        "    # 5. Outlier Removal (Train Only)\n",
        "    if is_train and TARGET in df.columns:\n",
        "        df = df[df[TARGET].notnull()].reset_index(drop=True)\n",
        "        df = df[df[\"num_females\"] <= 10]\n",
        "        df = df[df[\"num_males\"] <= 10]\n",
        "        df = df[df[\"mainland_stay_nights\"] <= 90]\n",
        "        df = df[df[\"island_stay_nights\"] <= 60]\n",
        "    \n",
        "    # 6. Fill Categorical Missing Values\n",
        "    categorical_cols = [\n",
        "        \"country\",\"age_group\",\"travel_companions\",\"main_activity\",\n",
        "        \"visit_purpose\",\"tour_type\",\"info_source\",\"arrival_weather\"\n",
        "    ]\n",
        "    for c in categorical_cols:\n",
        "        if c in df.columns:\n",
        "            mode_val = df[c].mode()[0] if not df[c].mode().empty else \"Unknown\"\n",
        "            df[c] = df[c].fillna(mode_val)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# FEATURE ENGINEERING (K-MEANS)\n",
        "# =====================================================\n",
        "\n",
        "def add_kmeans_features(train_df, test_df, n_clusters=6):\n",
        "    numeric_features = [\n",
        "        \"num_females\", \"num_males\", \"mainland_stay_nights\", \"island_stay_nights\",\n",
        "        \"days_booked_before_trip_ord\", \"total_trip_days_ord\"\n",
        "    ]\n",
        "    \n",
        "    X_train_num = train_df[numeric_features].copy()\n",
        "    X_test_num = test_df[numeric_features].copy()\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_num)\n",
        "    X_test_scaled = scaler.transform(X_test_num)\n",
        "    \n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_STATE, n_init=10)\n",
        "    train_df[\"kmeans_cluster\"] = kmeans.fit_predict(X_train_scaled)\n",
        "    test_df[\"kmeans_cluster\"] = kmeans.predict(X_test_scaled)\n",
        "    \n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# DATA PREPARATION & SMOTE\n",
        "# =====================================================\n",
        "\n",
        "print(\"Loading and preprocessing data...\")\n",
        "train_raw, test_raw = load_data()\n",
        "train_clean = preprocess_data(train_raw, is_train=True)\n",
        "test_clean = preprocess_data(test_raw, is_train=False)\n",
        "\n",
        "print(f\"Adding K-Means features (K={N_CLUSTERS})...\")\n",
        "train_clean, test_clean = add_kmeans_features(train_clean, test_clean, n_clusters=N_CLUSTERS)\n",
        "\n",
        "# Define Features\n",
        "numeric_features = [\n",
        "    \"num_females\", \"num_males\", \"mainland_stay_nights\", \"island_stay_nights\",\n",
        "    \"days_booked_before_trip_ord\", \"total_trip_days_ord\"\n",
        "]\n",
        "binary_features = [\n",
        "    \"is_first_visit\",\"intl_transport_included\",\"accomodation_included\",\n",
        "    \"food_included\",\"domestic_transport_included\",\"sightseeing_included\",\n",
        "    \"guide_included\",\"insurance_included\", \"has_special_req_bin\"\n",
        "]\n",
        "categorical_features = [\n",
        "    \"country\",\"age_group\",\"travel_companions\",\"main_activity\",\n",
        "    \"visit_purpose\",\"tour_type\",\"info_source\",\"arrival_weather\",\n",
        "    \"kmeans_cluster\"\n",
        "]\n",
        "\n",
        "all_features = numeric_features + binary_features + categorical_features\n",
        "\n",
        "# Prepare X and y\n",
        "X = train_clean[all_features]\n",
        "y = train_clean[TARGET]\n",
        "\n",
        "# Preprocessing Pipeline (Scaling/Encoding)\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numeric_features),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
        "    (\"bin\", \"passthrough\", binary_features)\n",
        "])\n",
        "\n",
        "print(\"Fitting preprocessor...\")\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "X_test_processed = preprocessor.transform(test_clean[all_features])\n",
        "\n",
        "# Apply SMOTE or Manual Upsampling\n",
        "print(\"Applying Class Balancing...\")\n",
        "if HAS_SMOTE:\n",
        "    print(\"Using SMOTE...\")\n",
        "    smote = SMOTE(random_state=RANDOM_STATE)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_processed, y)\n",
        "else:\n",
        "    print(\"Using Manual Upsampling...\")\n",
        "    # Combine X and y for resampling\n",
        "    train_data = pd.DataFrame(X_processed)\n",
        "    train_data[TARGET] = y.values\n",
        "    \n",
        "    major_class_size = train_data[TARGET].value_counts().max()\n",
        "    upsampled_dfs = []\n",
        "    for cls in train_data[TARGET].unique():\n",
        "        cls_df = train_data[train_data[TARGET] == cls]\n",
        "        cls_upsampled = resample(cls_df, \n",
        "                                 replace=True, \n",
        "                                 n_samples=major_class_size, \n",
        "                                 random_state=RANDOM_STATE)\n",
        "        upsampled_dfs.append(cls_upsampled)\n",
        "    \n",
        "    train_upsampled = pd.concat(upsampled_dfs)\n",
        "    X_resampled = train_upsampled.drop(columns=[TARGET]).values\n",
        "    y_resampled = train_upsampled[TARGET].values\n",
        "\n",
        "print(f\"Resampled shape: {X_resampled.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# BAYESIAN OPTIMIZATION (OPTUNA)\n",
        "# =====================================================\n",
        "\n",
        "# Split for Validation during Optimization\n",
        "X_train_opt, X_val_opt, y_train_opt, y_val_opt = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=RANDOM_STATE, stratify=y_resampled\n",
        ")\n",
        "\n",
        "def objective(trial):\n",
        "    # Hyperparameters\n",
        "    hidden_units = trial.suggest_categorical(\"hidden_units\", [32, 64, 128])\n",
        "    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
        "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"])\n",
        "    epochs = trial.suggest_int(\"epochs\", 10, 30)\n",
        "\n",
        "    input_dim = X_train_opt.shape[1]\n",
        "    num_classes = len(np.unique(y_resampled))\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(hidden_units, activation=activation),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(num_classes, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(lr),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train_opt, y_train_opt,\n",
        "        validation_data=(X_val_opt, y_val_opt),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    val_pred = np.argmax(model.predict(X_val_opt, verbose=0), axis=1)\n",
        "    val_acc = accuracy_score(y_val_opt, val_pred)\n",
        "\n",
        "    return val_acc\n",
        "\n",
        "print(\"Starting Bayesian Optimization...\")\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=10)  # Reduced trials for speed in this template\n",
        "\n",
        "print(\"Best Params:\", study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# TRAIN FINAL MODEL\n",
        "# =====================================================\n",
        "\n",
        "best_params = study.best_params\n",
        "input_dim = X_resampled.shape[1]\n",
        "num_classes = len(np.unique(y_resampled))\n",
        "\n",
        "final_model = keras.Sequential([\n",
        "    layers.Input(shape=(input_dim,)),\n",
        "    layers.Dense(best_params[\"hidden_units\"], activation=best_params[\"activation\"]),\n",
        "    layers.Dropout(best_params[\"dropout\"]),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "final_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(best_params[\"lr\"]),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Training final model on full resampled dataset...\")\n",
        "final_model.fit(\n",
        "    X_resampled, y_resampled,\n",
        "    epochs=best_params[\"epochs\"],\n",
        "    batch_size=best_params[\"batch_size\"],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# SAVE MODEL AND PIPELINE\n",
        "# =====================================================\n",
        "print(f\"Saving model to {MODEL_SAVE_PATH}...\")\n",
        "final_model.save(MODEL_SAVE_PATH)\n",
        "print(f\"Saving pipeline to {PIPELINE_SAVE_PATH}...\")\n",
        "joblib.dump(preprocessor, PIPELINE_SAVE_PATH)\n",
        "print(\"Saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# LOAD MODEL AND PREDICT\n",
        "# =====================================================\n",
        "print(\"Loading model and pipeline...\")\n",
        "loaded_model = keras.models.load_model(MODEL_SAVE_PATH)\n",
        "loaded_preprocessor = joblib.load(PIPELINE_SAVE_PATH)\n",
        "\n",
        "print(\"Predicting on test set...\")\n",
        "# Note: X_test_processed was already transformed earlier, but in a real scenario we'd do:\n",
        "# X_test_processed = loaded_preprocessor.transform(test_clean[all_features])\n",
        "\n",
        "test_probs = loaded_model.predict(X_test_processed)\n",
        "test_preds = np.argmax(test_probs, axis=1)\n",
        "\n",
        "# Save Predictions\n",
        "submission = pd.DataFrame({\n",
        "    ID_COL: test_clean[ID_COL],\n",
        "    TARGET: test_preds\n",
        "})\n",
        "submission.to_csv(SUBMISSION_PATH, index=False)\n",
        "print(f\"Predictions saved to {SUBMISSION_PATH}\")\n",
        "\n",
        "print(submission.head())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
