{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# =====================================================\n",
        "# STEP 1 — LOAD DATA\n",
        "# =====================================================\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/ML_Project/MultinomialClassification/Dataset/train.csv\"\n",
        "test_path  = \"/content/drive/MyDrive/ML_Project/MultinomialClassification/Dataset/test.csv\"\n",
        "\n",
        "\n",
        "\n",
        "df_raw = pd.read_csv(train_path)\n",
        "test_raw = pd.read_csv(test_path)\n",
        "\n",
        "TARGET = \"spend_category\"\n",
        "ID_COL = \"trip_id\"\n",
        "\n",
        "print(\"Original Training Shape:\", df_raw.shape)\n",
        "print(\"Original Test Shape:\", test_raw.shape)\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# HELPER — Convert Range (15-30, 90+) to numeric\n",
        "# =====================================================\n",
        "def range_to_mid(x):\n",
        "    x = str(x).strip()\n",
        "    if x.lower() in [\"none\", \"\", \"nan\", \"null\"]:\n",
        "        return np.nan\n",
        "    if \"+\" in x:\n",
        "        return float(x.replace(\"+\", \"\"))\n",
        "    if \"-\" in x:\n",
        "        a, b = x.split(\"-\")\n",
        "        return (float(a) + float(b)) / 2\n",
        "    try:\n",
        "        return float(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# STEP 2 — GLOBAL COLUMN DEFINITIONS\n",
        "# =====================================================\n",
        "binary_cols = [\n",
        "    \"is_first_visit\",\"intl_transport_included\",\"accomodation_included\",\n",
        "    \"food_included\",\"domestic_transport_included\",\"sightseeing_included\",\n",
        "    \"guide_included\",\"insurance_included\"\n",
        "]\n",
        "\n",
        "categorical_cols = [\n",
        "    \"country\",\"age_group\",\"travel_companions\",\"main_activity\",\n",
        "    \"visit_purpose\",\"tour_type\",\"info_source\",\"arrival_weather\"\n",
        "]\n",
        "\n",
        "numeric_count_cols = [\"num_females\",\"num_males\",\"mainland_stay_nights\",\"island_stay_nights\"]\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# STEP 3 — REMOVE NULL TARGETS FIRST\n",
        "# =====================================================\n",
        "removed_target_nulls = df_raw[TARGET].isnull().sum()\n",
        "print(\"Rows removed due to null spend_category:\", removed_target_nulls)\n",
        "\n",
        "df_raw = df_raw[df_raw[TARGET].notnull()].reset_index(drop=True)\n",
        "print(\"Training shape after removing null targets:\", df_raw.shape)\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# STEP 4 — MAIN PREPROCESSING FUNCTION\n",
        "# =====================================================\n",
        "def preprocess_raw_df(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Clean strings\n",
        "    for c in df.columns:\n",
        "        if df[c].dtype == object:\n",
        "            df[c] = df[c].astype(str).str.strip().str.rstrip(',')\n",
        "\n",
        "    # Binary processing\n",
        "    for c in binary_cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(str).str.strip().str.lower()\n",
        "            df[c] = df[c].replace({\n",
        "                \"yes\": 1,\n",
        "                \"no\": 0,\n",
        "                \"nan\": np.nan,\n",
        "                \"none\": np.nan,\n",
        "                \"null\": np.nan,\n",
        "                \"\": np.nan\n",
        "            })\n",
        "            df[c] = df[c].fillna(0).astype(int)\n",
        "\n",
        "    # Numeric count fields\n",
        "    for c in numeric_count_cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "    # =====================================================\n",
        "    # SAFE ORDINAL ENCODING FOR RANGE COLUMNS\n",
        "    # =====================================================\n",
        "\n",
        "    # Clean weird string values\n",
        "    def clean_str(x):\n",
        "        x = str(x).strip().lower()\n",
        "        if x in [\"nan\", \"none\", \"null\", \"\"]:\n",
        "            return np.nan\n",
        "        return x\n",
        "\n",
        "    # Clean raw string columns\n",
        "    if \"days_booked_before_trip\" in df.columns:\n",
        "        df[\"days_booked_before_trip_clean\"] = df[\"days_booked_before_trip\"].apply(clean_str)\n",
        "\n",
        "    if \"total_trip_days\" in df.columns:\n",
        "        df[\"total_trip_days_clean\"] = df[\"total_trip_days\"].apply(clean_str)\n",
        "\n",
        "    # Define ordinal mappings\n",
        "    ordinal_days_booked = {\n",
        "        \"1-7\": 1,\n",
        "        \"8-14\": 2,\n",
        "        \"15-30\": 3,\n",
        "        \"31-60\": 4,\n",
        "        \"61-90\": 5,\n",
        "        \"90+\": 6\n",
        "    }\n",
        "\n",
        "    ordinal_total_trip = {\n",
        "        \"1-6\": 1,\n",
        "        \"7-14\": 2,\n",
        "        \"15-30\": 3,\n",
        "        \"30+\": 4\n",
        "    }\n",
        "\n",
        "    # Map → Fill Missing → Convert to int\n",
        "    if \"days_booked_before_trip_clean\" in df.columns:\n",
        "        df[\"days_booked_before_trip_ord\"] = (\n",
        "            df[\"days_booked_before_trip_clean\"]\n",
        "                .map(ordinal_days_booked)\n",
        "        )\n",
        "\n",
        "        # Fill NaN with mode **of ordinal values**\n",
        "        df[\"days_booked_before_trip_ord\"].fillna(\n",
        "            df[\"days_booked_before_trip_ord\"].mode()[0],\n",
        "            inplace=True\n",
        "        )\n",
        "\n",
        "        df[\"days_booked_before_trip_ord\"] = df[\"days_booked_before_trip_ord\"].astype(int)\n",
        "\n",
        "    if \"total_trip_days_clean\" in df.columns:\n",
        "        df[\"total_trip_days_ord\"] = (\n",
        "            df[\"total_trip_days_clean\"]\n",
        "                .map(ordinal_total_trip)\n",
        "        )\n",
        "\n",
        "        # Fill NaN with mode of ordinal values\n",
        "        df[\"total_trip_days_ord\"].fillna(\n",
        "            df[\"total_trip_days_ord\"].mode()[0],\n",
        "            inplace=True\n",
        "        )\n",
        "\n",
        "        df[\"total_trip_days_ord\"] = df[\"total_trip_days_ord\"].astype(int)\n",
        "\n",
        "\n",
        "\n",
        "    # Special requirements → binary\n",
        "    if \"has_special_requirements\" in df.columns:\n",
        "        df[\"has_special_req_bin\"] = df[\"has_special_requirements\"].astype(str).apply(\n",
        "            lambda x: 0 if x.lower() in [\"none\", \"\", \"nan\"] else 1\n",
        "        )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# APPLY PREPROCESSING TO TRAIN & TEST\n",
        "# =====================================================\n",
        "df = preprocess_raw_df(df_raw).reset_index(drop=True)\n",
        "test_df = preprocess_raw_df(test_raw).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nAfter Base Preprocessing:\")\n",
        "print(df.shape)\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# STEP 5 — IMPUTATIONS (NO NaNs must remain)\n",
        "# =====================================================\n",
        "\n",
        "# Categorical mode fill\n",
        "for c in categorical_cols:\n",
        "    if c in df.columns:\n",
        "        mode = df[c].mode()[0]\n",
        "        df[c] = df[c].fillna(mode)\n",
        "        test_df[c] = test_df[c].fillna(mode)\n",
        "\n",
        "# =========================================================\n",
        "# OUTLIER REMOVAL (TRAIN ONLY)\n",
        "# And count number of rows removed per condition\n",
        "# =========================================================\n",
        "\n",
        "clean_df = df.copy()\n",
        "initial_rows = len(clean_df)\n",
        "\n",
        "outlier_info = {}\n",
        "\n",
        "# ----- num_females ≤ 14 -----\n",
        "before = len(clean_df)\n",
        "clean_df = clean_df[clean_df[\"num_females\"] <= 10]\n",
        "after = len(clean_df)\n",
        "outlier_info[\"num_females\"] = before - after\n",
        "\n",
        "# ----- Rule 1: num_males ≤ 13 -----\n",
        "before = len(clean_df)\n",
        "clean_df = clean_df[clean_df[\"num_males\"] <= 10]\n",
        "after_rule1 = len(clean_df)\n",
        "removed_rule1 = before - after_rule1\n",
        "before_rule2 = len(clean_df)\n",
        "\n",
        "# Save results\n",
        "outlier_info[\"num_males_threshold\"] = removed_rule1\n",
        "print(\"Removed (num_males > 20):\", removed_rule1)\n",
        "\n",
        "\n",
        "# ----- mainland_stay_nights ≤ 100 -----\n",
        "before = len(clean_df)\n",
        "clean_df = clean_df[clean_df[\"mainland_stay_nights\"] <= 90]\n",
        "after = len(clean_df)\n",
        "outlier_info[\"mainland_stay_nights\"] = before - after\n",
        "\n",
        "# ----- island_stay_nights ≤ 21 -----\n",
        "before = len(clean_df)\n",
        "clean_df = clean_df[clean_df[\"island_stay_nights\"] <= 60]\n",
        "after = len(clean_df)\n",
        "outlier_info[\"island_stay_nights\"] = before - after\n",
        "\n",
        "final_rows = len(clean_df)\n",
        "\n",
        "# =========================================================\n",
        "# PRINT OUTLIER REMOVAL SUMMARY\n",
        "# =========================================================\n",
        "print(\"\\n========== OUTLIER REMOVAL SUMMARY ==========\")\n",
        "for col, removed in outlier_info.items():\n",
        "    print(f\"{col}: removed {removed} rows\")\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "print(f\"Total rows removed: {initial_rows - final_rows}\")\n",
        "print(f\"Final Training Shape after Outlier Removal: {clean_df.shape}\")\n",
        "print(\"Test Shape (unchanged):\", test_df.shape)\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# STEP 5 — FINAL FEATURE DEFINITIONS (No NaNs left)\n",
        "# =====================================================\n",
        "\n",
        "numeric_features = [\n",
        "    \"num_females\",\n",
        "    \"num_males\",\n",
        "    \"mainland_stay_nights\",\n",
        "    \"island_stay_nights\",\n",
        "    \"days_booked_before_trip_ord\",\n",
        "    \"total_trip_days_ord\"\n",
        "]\n",
        "\n",
        "binary_features = binary_cols + [\"has_special_req_bin\"]\n",
        "\n",
        "categorical_features = categorical_cols\n",
        "\n",
        "all_features = numeric_features + binary_features + categorical_features\n",
        "\n",
        "clean_df = clean_df[all_features + [TARGET]]\n",
        "test_df_final = test_df[all_features]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pi1BaZuV0mk",
        "outputId": "6b637342-8e1f-4b6c-f233-f897788802bb",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Training Shape: (12654, 25)\n",
            "Original Test Shape: (5852, 24)\n",
            "Rows removed due to null spend_category: 34\n",
            "Training shape after removing null targets: (12620, 25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:149: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"days_booked_before_trip_ord\"].fillna(\n",
            "/tmp/ipython-input-1170839011.py:163: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"total_trip_days_ord\"].fillna(\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:91: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[c] = df[c].replace({\n",
            "/tmp/ipython-input-1170839011.py:149: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"days_booked_before_trip_ord\"].fillna(\n",
            "/tmp/ipython-input-1170839011.py:163: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"total_trip_days_ord\"].fillna(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After Base Preprocessing:\n",
            "(12620, 30)\n",
            "Removed (num_males > 20): 8\n",
            "\n",
            "========== OUTLIER REMOVAL SUMMARY ==========\n",
            "num_females: removed 28 rows\n",
            "num_males_threshold: removed 8 rows\n",
            "mainland_stay_nights: removed 27 rows\n",
            "island_stay_nights: removed 8 rows\n",
            "---------------------------------------------\n",
            "Total rows removed: 71\n",
            "Final Training Shape after Outlier Removal: (12549, 30)\n",
            "Test Shape (unchanged): (5852, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BASE = \"/content/drive/MyDrive/ML_Project/MultinomialClassification/MulticlassLR_WithClustering\"\n",
        "\n",
        "# =====================================================\n",
        "# STEP 5 — TRAIN/VAL/TEST SPLITTING (READY)\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\nREADY FOR SPLITTING — No NaNs left.\")\n",
        "print(\"Train shape:\", clean_df.shape)\n",
        "print(\"Test final shape:\", test_df_final.shape)\n",
        "\n",
        "print(\"Next: perform splitting...\")\n",
        "\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# STEP 5 — TRAIN/VAL/TEST SPLITTING\n",
        "# =====================================================\n",
        "\n",
        "# Better method:\n",
        "#  → First create 80% main training, 20% held-out set\n",
        "train_main, temp = train_test_split(\n",
        "    clean_df, test_size=0.20, stratify=clean_df[TARGET], random_state=42\n",
        ")\n",
        "\n",
        "# Validation = 20% of main training\n",
        "train_80, val_80 = train_test_split(\n",
        "    train_main, test_size=0.20, stratify=train_main[TARGET], random_state=42\n",
        ")\n",
        "\n",
        "# 20% dataset\n",
        "train_20, val_20 = train_test_split(\n",
        "    temp, test_size=0.20, stratify=temp[TARGET], random_state=42\n",
        ")\n",
        "\n",
        "print(\"80% train:\", train_80.shape)\n",
        "print(\"80% val:\", val_80.shape)\n",
        "print(\"20% train:\", train_20.shape)\n",
        "print(\"20% val:\", val_20.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3Vo1XXlsYFu",
        "outputId": "7f794f32-b551-4052-80b5-ab47fec838ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "READY FOR SPLITTING — No NaNs left.\n",
            "Train shape: (12549, 26)\n",
            "Test final shape: (5852, 25)\n",
            "Next: perform splitting...\n",
            "80% train: (8031, 26)\n",
            "80% val: (2008, 26)\n",
            "20% train: (2008, 26)\n",
            "20% val: (502, 26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed → 80_skewed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed → 80_nonskewed\n",
            "Completed → 20_skewed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed → 20_nonskewed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =====================================================\n",
        "# STEP 6 — FUNCTION TO MAKE SKEWED AND NON-SKEWED\n",
        "# =====================================================\n",
        "def make_skewed(df):\n",
        "    # keep natural distribution\n",
        "    return df.copy()\n",
        "\n",
        "def make_nonskewed(df):\n",
        "    # upsample minority classes\n",
        "    major_size = df[TARGET].value_counts().max()\n",
        "    frames = []\n",
        "    for cls in df[TARGET].unique():\n",
        "        cls_df = df[df[TARGET]==cls]\n",
        "        cls_up = resample(cls_df, replace=True, n_samples=major_size, random_state=42)\n",
        "        frames.append(cls_up)\n",
        "    return pd.concat(frames)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4nd_5B_75FZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, RBF\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =====================================================\n",
        "# STEP 6.5 — MANUAL BAYESIAN HYPERPARAMETER TUNING (No Optuna)\n",
        "# =====================================================\n",
        "\n",
        "def bayesian_tune_lr(X_train, y_train, X_val, y_val, n_iter=20):\n",
        "\n",
        "    # Search space\n",
        "    search_space = {\n",
        "        \"C\": np.logspace(-4, 1, 50),     # 50 candidates\n",
        "    }\n",
        "\n",
        "    # Random initial samples\n",
        "    samples = list(ParameterSampler(search_space, n_iter, random_state=42))\n",
        "\n",
        "    results = []\n",
        "    scores = []\n",
        "\n",
        "    # Kernel for Bayesian optimizer\n",
        "    kernel = Matern(nu=2.5) + WhiteKernel()\n",
        "\n",
        "    for params in samples:\n",
        "\n",
        "        model = LogisticRegression(\n",
        "            C=params[\"C\"],\n",
        "            penalty=\"l2\",\n",
        "            multi_class=\"multinomial\",\n",
        "            solver=\"lbfgs\",\n",
        "            max_iter=500\n",
        "        )\n",
        "\n",
        "        pipe = Pipeline([\n",
        "            (\"prep\", preprocess),\n",
        "            (\"lr\", model)\n",
        "        ])\n",
        "\n",
        "        pipe.fit(X_train, y_train)\n",
        "        pred = pipe.predict(X_val)\n",
        "        score = accuracy_score(y_val, pred)\n",
        "\n",
        "        results.append(params)\n",
        "        scores.append(score)\n",
        "\n",
        "    # Fit a Gaussian Process on (C → accuracy)\n",
        "    C_vals = np.array([r[\"C\"] for r in results]).reshape(-1, 1)\n",
        "    scores = np.array(scores)\n",
        "\n",
        "    gp = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
        "    gp.fit(C_vals, scores)\n",
        "\n",
        "    # Predict best C in range\n",
        "    C_fine = np.logspace(-4, 1, 200).reshape(-1, 1)\n",
        "    preds = gp.predict(C_fine)\n",
        "\n",
        "    best_C = C_fine[np.argmax(preds)][0]\n",
        "\n",
        "    print(\"\\n===== Bayesian Tuning Complete (No Optuna) =====\")\n",
        "    print(\"Best C:\", best_C)\n",
        "\n",
        "    return {\"C\": best_C}\n"
      ],
      "metadata": {
        "id": "5Wb17Ad15M46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# STEP 7 — PIPELINE (OHE + SCALER + MULTINOMIAL LR)\n",
        "# =====================================================\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numeric_features),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "    (\"bin\", \"passthrough\", binary_features)\n",
        "])\n",
        "\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    max_iter=500,\n",
        "    solver='lbfgs'\n",
        ")\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"prep\", preprocess),\n",
        "    (\"lr\", model)\n",
        "])"
      ],
      "metadata": {
        "id": "Or36tmfP5brU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# STEP 8 — TRAINING FUNCTION\n",
        "# =====================================================\n",
        "def run_and_save(mode_name, train_df, val_df, folder):\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    X_train = train_df[all_features]\n",
        "    y_train = train_df[TARGET]\n",
        "\n",
        "    X_val = val_df[all_features]\n",
        "    y_val = val_df[TARGET]\n",
        "\n",
        "    # Train\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Validation results\n",
        "    val_pred = pipe.predict(X_val)\n",
        "    val_acc = accuracy_score(y_val, val_pred)\n",
        "\n",
        "    # Save val classification report\n",
        "    with open(f\"{folder}/val_classification_report.txt\", \"w\") as f:\n",
        "        f.write(classification_report(y_val, val_pred))\n",
        "\n",
        "    # Train accuracy\n",
        "    train_pred = pipe.predict(X_train)\n",
        "    train_acc = accuracy_score(y_train, train_pred)\n",
        "\n",
        "    # Save accuracy summary\n",
        "    with open(f\"{folder}/accuracy_summary.txt\", \"w\") as f:\n",
        "        f.write(f\"Train accuracy: {train_acc}\\n\")\n",
        "        f.write(f\"Validation accuracy: {val_acc}\\n\")\n",
        "\n",
        "    # Predict test dataset\n",
        "    final_pred = pipe.predict(test_df_final)\n",
        "\n",
        "    pd.DataFrame({\n",
        "        ID_COL: test_df[ID_COL],\n",
        "        TARGET: final_pred\n",
        "    }).to_csv(f\"{folder}/predictions_{mode_name}.csv\", index=False)\n",
        "\n",
        "    print(f\"Completed → {mode_name}\")"
      ],
      "metadata": {
        "id": "pzzoH6hF5e2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# STEP 9 — RUN ALL 4 MODES\n",
        "# =====================================================\n",
        "\n",
        "\n",
        "os.makedirs(BASE, exist_ok=True)\n",
        "\n",
        "tasks = [\n",
        "    (\"80_skewed\",     make_skewed(train_80),     val_80),\n",
        "    (\"80_nonskewed\",  make_nonskewed(train_80),  val_80),\n",
        "    (\"20_skewed\",     make_skewed(train_20),     val_20),\n",
        "    (\"20_nonskewed\",  make_nonskewed(train_20),  val_20),\n",
        "]\n",
        "\n",
        "for name, tr, va in tasks:\n",
        "    folder = f\"{BASE}/{name}\"\n",
        "    run_and_save(name, tr, va, folder)\n"
      ],
      "metadata": {
        "id": "bBUeT4IJ5h1R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}